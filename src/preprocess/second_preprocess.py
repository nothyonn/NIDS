import json
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

# ========================================
# 0. ê²½ë¡œ ì„¤ì •
# ========================================
ROOT_DIR = Path(__file__).resolve().parents[2]  # D:\NIDS
INPUT_PATH = ROOT_DIR / "processed" / "master_raw.csv"

OUTPUT_DIR = ROOT_DIR / "processed"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

TRAIN_OUT = OUTPUT_DIR / "flows_train_scaled.parquet"
VAL_OUT   = OUTPUT_DIR / "flows_val_scaled.parquet"
TEST_OUT  = OUTPUT_DIR / "flows_test_scaled.parquet"
CONFIG_OUT = OUTPUT_DIR / "preprocess_config.json"

print("ROOT_DIR   :", ROOT_DIR)
print("INPUT_PATH :", INPUT_PATH)


# ========================================
# 1. master_raw ë¡œë“œ
# ========================================
print("\n[LOAD] master_raw.csv ë¡œë“œ ì¤‘...")
df = pd.read_csv(INPUT_PATH)
print(f"ì´ í–‰ ìˆ˜: {len(df):,}")
print(f"ì»¬ëŸ¼ ìˆ˜: {df.shape[1]}")

if "Label" not in df.columns:
    raise RuntimeError("Label ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ì¤‘ë‹¨.")


# ========================================
# 2. Port / Protocol ì¸ë±ìŠ¤ ìƒì„±
#    - í¬íŠ¸: ë¹ˆë„ ìƒìœ„ Nê°œ + ë‚˜ë¨¸ì§€ OTHER
#    - í”„ë¡œí† ì½œ: ë°œê²¬ëœ ê°’ ì „ë¶€ ì¸ë±ìŠ¤ + ì—†ìœ¼ë©´ OTHER
# ========================================

# ìˆ«ì ë³€í™˜ (ì—ëŸ¬ëŠ” NaN)
df["Source Port"] = pd.to_numeric(df["Source Port"], errors="coerce")
df["Destination Port"] = pd.to_numeric(df["Destination Port"], errors="coerce")
df["Protocol"] = pd.to_numeric(df["Protocol"], errors="coerce")

# 2-1. Port ì¸ë±ìŠ¤
print("\n[ENCODE] Port ì¸ë±ìŠ¤ ìƒì„±...")

all_ports = pd.concat([df["Source Port"], df["Destination Port"]], axis=0)
all_ports = all_ports.dropna().astype(int)

# ë¹ˆë„ ìƒìœ„ Nê°œ í¬íŠ¸ëŠ” ê°œë³„ ì¹´í…Œê³ ë¦¬, ë‚˜ë¨¸ì§€ëŠ” OTHER
TOP_N_PORTS = 15
top_ports = all_ports.value_counts().head(TOP_N_PORTS).index.tolist()
top_ports = sorted(top_ports)  # ì •ë ¬í•´ì„œ ì¸ë±ìŠ¤ ê³ ì •

port_idx_map = {}
current_idx = 0
for p in top_ports:
    port_idx_map[int(p)] = current_idx
    current_idx += 1

other_port_idx = current_idx  # ë‚˜ë¨¸ì§€ í¬íŠ¸ëŠ” ì—¬ê¸°ë¡œ

def map_port(p):
    try:
        p_int = int(p)
    except (TypeError, ValueError):
        return other_port_idx
    return port_idx_map.get(p_int, other_port_idx)

df["sport_idx"] = df["Source Port"].map(map_port)
df["dport_idx"] = df["Destination Port"].map(map_port)

print("Port ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ (including OTHER):", other_port_idx + 1)

# 2-2. Protocol ì¸ë±ìŠ¤
print("\n[ENCODE] Protocol ì¸ë±ìŠ¤ ìƒì„±...")

protos = df["Protocol"].dropna().astype(int).value_counts().index.tolist()
protos = sorted(protos)

proto_idx_map = {}
for i, p in enumerate(protos):
    proto_idx_map[int(p)] = i

proto_other_idx = len(proto_idx_map)  # í˜¹ì‹œ ì—†ëŠ” ê°’ ë“¤ì–´ì˜¤ë©´ OTHER

def map_proto(v):
    try:
        v_int = int(v)
    except (TypeError, ValueError):
        return proto_other_idx
    return proto_idx_map.get(v_int, proto_other_idx)

df["proto_idx"] = df["Protocol"].map(map_proto)

print("Protocol ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ (including OTHER):", proto_other_idx + 1)


# ========================================
# 3. Train / Val / Test Stratified Split
# ========================================
print("\n[SPLIT] Train 70% / Val 15% / Test 15% (Label ê¸°ì¤€ Stratified)")

train_df, temp_df = train_test_split(
    df,
    test_size=0.30,
    stratify=df["Label"],
    random_state=42,
    shuffle=True,
)

val_df, test_df = train_test_split(
    temp_df,
    test_size=0.50,
    stratify=temp_df["Label"],
    random_state=42,
    shuffle=True,
)

print(f"Train: {len(train_df):,}")
print(f"Val  : {len(val_df):,}")
print(f"Test : {len(test_df):,}")


# ========================================
# 4. Numeric feature ìŠ¤ì¼€ì¼ë§
#    - train ê¸°ì¤€ìœ¼ë¡œ medianâ†’NaN ì±„ìš°ê¸° â†’ mean/std ê³„ì‚°
#    - Port/Protocol index, IP, Timestamp, Label ë“±ì€ ìŠ¤ì¼€ì¼ë§ X
# ========================================

print("\n[SCALE] Numeric feature ìŠ¤ì¼€ì¼ë§ ì‹œì‘...")

# ìŠ¤ì¼€ì¼ë§ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ë“¤
exclude_for_scaling = [
    "Source IP",
    "Destination IP",
    "Timestamp",
    "Label",
    "source_file",
    "Source Port",
    "Destination Port",
    "Protocol",
    "sport_idx",
    "dport_idx",
    "proto_idx",
]

# ìˆ«ì íƒ€ì… ì»¬ëŸ¼ ì¤‘ì—ì„œ ì œì™¸ëŒ€ìƒ ë¹¼ê³  ìŠ¤ì¼€ì¼ë§ ëŒ€ìƒ ì„ ì •
num_candidates = train_df.select_dtypes(
    include=["int64", "float64", "float32", "Int64"]
).columns.tolist()

numeric_cols = [c for c in num_candidates if c not in exclude_for_scaling]

print("ìŠ¤ì¼€ì¼ë§ ëŒ€ìƒ numeric ì»¬ëŸ¼ ìˆ˜:", len(numeric_cols))
print("ì˜ˆì‹œ:", numeric_cols[:10])

# 4-A. NaN ì±„ìš°ê¸° (train median ê¸°ì¤€)  ğŸ”¥ ì¶”ê°€ëœ ë¶€ë¶„
train_medians = train_df[numeric_cols].median()

train_df[numeric_cols] = train_df[numeric_cols].fillna(train_medians)
val_df[numeric_cols]   = val_df[numeric_cols].fillna(train_medians)
test_df[numeric_cols]  = test_df[numeric_cols].fillna(train_medians)

# train ê¸°ì¤€ mean/std ê³„ì‚°
means = train_df[numeric_cols].mean()
stds = train_df[numeric_cols].std().replace(0, 1e-6)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

def apply_scaling(df_part: pd.DataFrame) -> pd.DataFrame:
    df_part = df_part.copy()
    df_part[numeric_cols] = (df_part[numeric_cols] - means) / stds
    return df_part

train_scaled = apply_scaling(train_df)
val_scaled = apply_scaling(val_df)
test_scaled = apply_scaling(test_df)


# ========================================
# 5. ê²°ê³¼ ì €ì¥ (Parquet + ì„¤ì • JSON)
# ========================================

print("\n[SAVE] Parquet ì €ì¥ ì¤‘...")
train_scaled.to_parquet(TRAIN_OUT, index=False)
val_scaled.to_parquet(VAL_OUT, index=False)
test_scaled.to_parquet(TEST_OUT, index=False)

print("ì €ì¥ ì™„ë£Œ:")
print(" -", TRAIN_OUT)
print(" -", VAL_OUT)
print(" -", TEST_OUT)

print("\n[CONFIG] preprocess_config.json ì €ì¥ ì¤‘...")

config = {
    "numeric_cols": numeric_cols,
    "port_idx_map": {str(k): int(v) for k, v in port_idx_map.items()},
    "other_port_idx": int(other_port_idx),
    "proto_idx_map": {str(k): int(v) for k, v in proto_idx_map.items()},
    "proto_other_idx": int(proto_other_idx),
    "scaler": {
        "mean": means.to_dict(),
        "std": stds.to_dict(),
    },
}

# ë©€í‹°ë¼ë²¨ìš© í´ë˜ìŠ¤ ëª©ë¡ (ìœˆë„ìš° íƒ€ê²Ÿ ë§Œë“¤ ë•Œ ì‚¬ìš©)
config["label_classes"] = sorted(df["Label"].unique().tolist())

with open(CONFIG_OUT, "w", encoding="utf-8") as f:
    json.dump(config, f, indent=2)

print(" -", CONFIG_OUT)
print("\n[DONE] 2ì°¨ ì „ì²˜ë¦¬ ì™„ë£Œ.")
